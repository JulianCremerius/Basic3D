<!--

author: Julian Cremerius (FAU/SODa)

comment: Dieser Kurs soll in die Grundprinzipien der photographischen 3D-Digitalisierung einf√ºhren.

version: 0.1.0
email: julian.cremerius@fau.de

icon: ./res/soda.png


mode: Textbook

dark: false

language: de

@onload
window.LIA.settings.theme = "yellow"
@end


-->

# Basics 3D

---

<!-- style="display: block; float: none; width: 80%; margin-left: auto; margin-right: auto;" -->
![Nike - Von Statue zum 3D Modell](res/nike_slow.gif)

Willkommen zu unserer Basic-3D-Pipeline OER!
<br><br>
Im Zuge dieses kleinen Tutorials wollen wir euch mit dem 3D-Digitalisierungsprozess in seiner einfachsten Form und den grundlegenden Prinzipien vertraut machen. 
<br><br>
Es werden daher keinerlei Grundkenntnisse vorausgesetzt und bedarf auch keiner kostenpflichtiger Software.<br>
Die erzielten Resultate k√∂nnen bereits sehr schnell erstaunliche Qualit√§t erreichen, bleiben aber nat√ºrlich hinter den M√∂glichkeiten professioneller Digitalisierungsoftware & -prozesse zur√ºck.<br>
Wer im Nachgang das Bed√ºrfnis versp√ºrt, die Qualit√§t seines Vorgehens und der Ergebnisse zu steigern, dem empfehlen wir an angebrachter Stelle auch modulare und schrittweise einsetzbare Aufwertungen der eingesetzten Mittel und Methoden (Aufnahmesetup, Rekonstruktionssoftware, Nachbearbeitung).

<br><br>

---

<br><br>

<div style="overflow:auto">
  <div style="float:left;width:48%">
    <img style="float:right;width:50%" src="res/funding_EU.png" alt="">
  </div>
  <div style="float:right;width:48%">
    <img style="float:left;width:80%" src="res/funding_BMFTR.jpg" alt="">
  </div>
</div>

#### Was ist unser Ziel?

Der 3D-Digitalisierung wird vielerseits noch mit viel Unverst√§ndnis und gro√üem Respekt begegnet. Die damit einhergende technische Herausforderung kann schnell abschreckend erscheinen. Wir wollen mit dieser Ressource allen, die sich in dieser Situation wiederfinden einen Einblick und Zugang zur angewandten 3D-Digitalisierung an die Hand geben. Auch wenn es bei der professionellen Anwendung durchaus H√ºrden zu √ºberwinden gibt, ist der wichtigste und vielleicht schwierigste Schritt auf dem Weg dorthin, den Anfang zu wagen.
Im Folgenden befassen wir uns mit der zug√§nglichsten und wohl verbreitetsten Methode, der Photogrammetrie.
Um an die entsprechende Methodik heranzuf√ºhren und zur 3D-Digitalisierung zu motivieren, versuchen wir daher gemeinsam:

- Das Konzept und die Algorithmik hinter der 3D-Digitalisierung mittels Photogrammetrie zu verstehen
- Mit den grundlegenden Arbeitsschritten und Prozessen der 3D-Digitalisierung bekannt zu werden
- Einen Ansatzpunkt & Motivation zu bekommen, um in Zukunft auch selbst Photogrammetrie einzusetzen
- Interesse zu wecken und Ausblicke geben, um Photogrammetrie nicht nur Einzusetzen, sondern auch in Zukunft weiter zu Vertiefen und den eigenen Arbeitsprozess modular zu verbessern
  
Diese Lernressource ist nicht an Leute gerichtet, die in ihrem Arbeitsalltag bereits erfolgreich und routiniert 3D-Digitalisate erschaffen.

#### Der Weg zum professionellen Digitalisieren

Auch wenn der Umfang des Tutorials im Sinne der Einsteigerfreundlichkeit √ºberschaubar gew√§hlt ist, versuchen wir den 3D-Digitalisierungsprozess in seiner G√§nze zu umrei√üen.  Wir sprechen daher bisweilen Arbeitsschritte an,
die f√ºr erste Versuche & Hobbym√§√üige Aufnahmen nicht vonn√∂ten sein m√∂gen, im √úbergang hin zum professionellem Einsatz aber stark an Relevanz gewinnen.

Der Prozess ist der √úbersicht halber in drei Arbeitsschritte aufgeteilt - Die Aufnahme, die Nachbearbeitung & die Publikation des Modells.
F√ºr den weiterf√ºhrenden Einstieg in die professionellen Digitalisierungsarbeit empfehlen wir, die einzelnen Schritte des dargestellten Arbeitsablaufs mit steigendem Qualit√§tsanspruch modular auszubauen und die verwendete Soft- & Hardware schrittweise durch hochwertigere Alternativen zu ersetzen. Der Digitalisierungsprozess kann mit nahezu unbegrenztem Aufwand und Mitteleinsatz durchgef√ºhrt werden. In vielen F√§llen ist die gew√ºnschte oder notwendige Qualit√§t aber bereits mit moderatem Einsatz erreichbar.

#### Wieso PolyCam & Sketchfab?

Wir verwenden im Laufe des Tutorials sowohl die Smartphone-App [**Polycam**](https://poly.cam) als auch den Webservice [**Sketchfab**](https://sketchfab.com). <br><br><img src="res/Polycam_logo.svg" alt="" style="float:right;width:33%">
W√§hrend beiderlei Software kostenpflichtige Features hinter Abonnements zur√ºckhalten, empfehlen und verlangen wir in diesem Tutorial ***nicht*** den Abschluss eines solchen Abonnements - alle im Folgenden notwendigen Features stehen vollkommen kostenfrei zur Verf√ºgung und verlangen lediglich die Erstellung eines jeweiligen Benutzeraccounts.<br> 
Aus diesem Grund pr√§sentieren und besprechen wir zu beiden Programmen Alternativen, die bei Bedarf ebenfalls eingesetzt werden k√∂nnen - einige Arbeitsschritte unterscheiden sich in diesem Fall nat√ºrlich.<br><br>

<img src="res/sketchfab-logo-text.png" alt="" style="float:right;width:30%;margin-bottom:20px">
Es besteht weder eine Kooperation mit den verwendeten Diensten eine kommerzielle Empfehlung der Dienste unsererseits. Die Festlegung auf spezifische Dienste dient ausschlie√ülich der konsistenten Darstellung von spezifischen Anwendungsbeispielen.<br> 
Grund f√ºr die Wahl der betreffenden Software ist unser prim√§res Ziel der Bekanntmachung & Vorstellung der Methodik.
Da es sich dementsprechend um ein Einsteiger- und Ausprobier-Tutorial handelt, sollen keine Kosten & minimaler Aufwand hervorgerufen werden (reine Open-Source Software ist h√§ufig Einarbeitungsintensiv).
Um weiterhin keine Anforderungen im Bezug auf teure & leistungsf√§hige Hardware zu stellen, beschr√§nken wir uns auf Smartphone-Apps & Web-Apps, die auf jedem mobilen Ger√§t verwendet werden k√∂nnen.
<br> 
Wir hoffen, durch unsere Wahl einen reibungslosen Ablauf und schnelle Erfolge bereiten zu k√∂nnen, unterst√ºtzen aber jederzeit die Wahl alternativer Software.<br><br>

> *‚ö†Ô∏è Hinweis - Es handelt sich bei beiden Softwares um ****Cloud****-basierte Dienste, die im Zuge der Photogrammetrie aufgenommenen Bilder sowie das resultierende Modell werden an externe Server √ºbermittelt. Vorteil des Nutzers ist in diesem Falle, nicht die Rechenleistung f√ºr die Rekonstruktion stellen zu m√ºssen und bei sp√§terer Webpublikation eine dauerhafte Verf√ºgbarkeit des Modells garantieren zu k√∂nnen. Es sollte aber vermieden werden, vertrauliche Daten & Aufnahmen derartig zu verarbeiten.*




## Part 1 - Aufnahme

Im ersten Kapitel des Tutorials besch√§ftigen wir uns mit dem Aufnahmeprozess selbst. Um die Funktionsweise und Limitationen der Methode zu verstehen, schauen wir uns zuerst die Algorithmik an, die der Photogrammetrie zugrunde liegt.
Danach folgen einige notwendige Vorbereitungsschritte, bevor wir uns schlussendlich dem Aufnahmprozess selbst widmen.


#### Theorie-Einblick

{{0-1}}
**********
Hinter jeder herk√∂mmlichen Photogrammetrie-Software versteckt sich die sogenannte *Structure-from-Motion*  Methode.
Im Folgenden geben wir einen kleinen √úberblick √ºber die grundlegende Algorithmik - ein tieferes technisches Verst√§ndnis der Methodik ist f√ºr die 3D-Modell-Aufnahme zwar nicht zwingend notwendig, kann aber oft helfen, Fehler und entsprechende Fehlerquellen bei der Anwendung schnell zu identifizieren und zu vermeiden.
<br><br>
*Structure-from-Motion* (*SfM*), also 'Struktur aus Bewegung' (bzw. frei √ºbersetzt und ausf√ºhrlicher - 'Erkennung 3-dimensionaler Strukturen durch Betrachtung aus verschiedenen Perspektiven') bezeichnet das allgemeine Problem, die 3-dimensionale Form & Geometrie eines Objekts auf Basis mehrerer 2-dimensionaler Beobachtungen herausfinden bzw. berechnen zu k√∂nnen. In der *Computer Vision*-Forschung hat sich hierf√ºr ein gefestigter, computergest√ºtzter Prozess etabliert, den wir uns nun genauer anschauen wollen.

---
<br><br>
**********

{{1-2}}
**********
Wie aus der Methoden-Bezeichnung bereits hervorgeht, ist f√ºr die *SfM*-Aufnahme eine Reihe von regul√§ren 2D-Fotoaufnahmen notwendig.
Es handelt sich im Grunde um klassische Objektphotographie, die aus mehreren Blickwinkeln wiederholt wird, bis eine ausreichende Abdeckung des Objekts aus allen Richtung erreicht ist. (Die Fotografischen Standards & Anforderungen unterscheiden sich jedoch etwas von denen der klassischen Objektphotographie.) <br><br><br>

<div style="overflow:auto">
    <img src="res/photography.svg" style="float:left;width:40%;margin-top:8%"/>
    <img src="res/setup_photo.svg" style="float:right;width:40%"/>
</div>

---
<br><br>
**********

{{2-3}}
**********
Bevor das Modell selbst aber berechnet werden kann, fehlt an dieser Stelle noch eine wichtige Information - In welchem r√§umlichen Verh√§ltnis stehen die einzelnen Kameraperspektiven zueinander?
Da entweder die Kamera oder das Objekt zwischen den Aufnahmen bewegt werden muss und eine technische Messung der Bewegungen h√§ufig nicht akkurat genug ist, wird versucht diese r√§umlichen Verh√§ltnisse aus den Bildern selbst zu bestimmen. <br><br><br>

<div style="overflow:auto">
    <img src="res/triangulation_photo_problem.svg" alt="Problemstellung der Photogrammetrie" style="float:left;width:40%"/>
    <img src="res/triangulation_photo.svg" alt="L√∂sungsansatz der Photogrammetrie" style="float:right;width:40%"/>
</div>

<!--- TODO: subtitles with explanation--->

---
<br><br>
**********

{{3-4}}
**********
F√ºr diese Berechnung ist es notwendig, visuelle *Features* (= Merkmale) der abgebildeten Szene in einer Vielzahl verschiedener Bilder wiederzuerkennen. Hierf√ºr kommen sogenannte *Feature Detection*-Algorithmen zum Einsatz, insbesondere *SIFT* (= *Scale-invariant feature transform*, optimiert f√ºr Wiedererkennung von Merkmalen trotz verschiedener Gr√∂√üen/Rotation/Belichtung) oder *SURF* (= *Sped-up robust features*, ein Kompromiss zwischen schnellerer Laufzeit und robusten Ergebnissen). Das Ergebnis dieser *Feature Detection* sieht wie folgt aus: <br><br><br>

{{3-4}}
<div style="overflow:auto">
    <img src="res/features_1.png" alt="SIFT Feature Detection (Bsp 1)" style="float:left;width:48%;"/>
    <img src="res/features_2.png" alt="SIFT Feature Detection (Bsp 2)" style="float:right;width:48%;"/>
</div>

<!--- TODO: subtitles with explanation--->

---
<br><br>
**********

{{4-5}}
**********
Da all diese *Features* aufgrund ihres hohen Wiedererkennungswertes ausgesucht wurden, ist nun ein *Feature Matching* (= Merkmalsabgleich) m√∂glich, wobei zu allen *Features* eines Bildes korrespondierende 'Partner'-*Features* in anderen Bildern gesucht werden. <br><br><br>

<div style="overflow:auto">
    <img src="res/matching.png" alt="SIFT Feature Matching" style="float:center;width:100%;"/>
</div>

<!--- TODO: subtitles with explanation--->

---
<br><br>
**********

{{5-7}}
Sofern an diesem Punkt ausreichend Zusammenh√§nge zwischen den Kameraperspektiven und den von ihnen gesehenen Szenenbereichen registriert wurden, ist nun eine Triangulation der Kamerapositionen zueinander m√∂glich.
Ausgehend von einer beliebigen Kameraperspektive und den erkannten *Features*, werden nach und nach zus√§tzliche Perpektiven ausgerechnet und in die Szene hinzugef√ºgt. Diese Berechnungen liefern uns zwei wichtige Ergebnisse:

{{5-6}}
**********
* Die r√§umlichen Verh√§ltnisse zwischen den Kameras 

![SfM-Rekonstruktion der Szene](res/sfm_result.png)
**********

{{6-7}}
**********
* Die sog. *Sparse Point Cloud* (= d√ºnn besetzte Punktewolke)

![Die *Sparse Point Cloud*](res/sparse_pc.png)

---
<br><br>
**********

{{7-8}}
**********
Auf Basis der *Sparse Point Cloud* wird danach noch einmal jedes Bild betrachtet, und Bildpunkte, die zuvor nicht bereits als *Features* genutzt wurden, werden verwendet, um die Punktwolke langsam zu verdichten.
Wenn alle Bilder noch einmal durchgegangen wurden, erhalten wir die *Dense Point Cloud* (= dicht besetzte Punktwolke).

![Die *Dense Point Cloud*](res/dense_pc.png)

---
<br><br>
**********

{{8-9}}
**********
Die Verwendung von Punktwolken zur Geometriedarstellung hat allerdings diverse Nachteile und wird von vieler Software und auch Hardware nicht effizient oder sogar √ºberhaupt nicht unterst√ºtzt.
Daher ist h√§ufig die Umrechnung zu einem *(Polygon) Mesh* (= Polygonnetz, √ºblichste 3D-Geometriedarstellung) w√ºnschenswert, viele Photogrammetrie-Programme f√ºhren diesen Schritt auch automatisch mit aus.
Nachdem das *Mesh* berechnet wurde und die Texturen darauf projiziert wurden, erhalten wir schlie√ülich das Endresultat der Photogrammetrie: <br><br><br>

<div>
    <img src="res/mesh.png" alt="Berechnung des *Polygon Mesh*" style="float:left;width:48%"/>
    <img src="res/textures.png" alt="Projektion der Farbtextur auf das *Mesh*" style="float:right;width:48%"/>
</div>

<!--- TODO: subtitles with explanation--->

---

<br><br>
**********

#### Vorbereitung - Aufnahmeger√§t


Setup einer Aufnahme-App
===


Bevor wir uns mit der 3D-Aufnahme selbst besch√§ftigen k√∂nnen, braucht es nun selbstverst√§ndlich ein Aufnahme-Setup. <br>
Im Falle der Photogrammetrie kann so ein Aufnahme-Setup zwar fast beliebig aufwendig und teuer werden (DSLR Kamera, Studio-Beleuchtung, Polfilter, elektr. Drehteller, etc), aber zum Gl√ºck auch fast beliebig schlicht gehalten werden. <br>
Die einzige unabdingbare Voraussetzung ist eine Kamera - √ºber die bereits jedes heutige Smartphone verf√ºgt.
<br><br> <!--- TODO: restructure? --->
Wir k√∂nnten also direkt anfangen und eine Reihe Photos mit dem Smarthphone machen, die wir dann sp√§ter an eine Photogrammetrie-Software (wie z.B. **MetaShape**, **RealityCapture**) weitergeben, um uns ein Modell zu berechnen.<br>
Inzwischen gibt es allerdings auch viele benutzerfreundliche, Smartphone-basierte Photogrammetrie-Apps, die den ganzen Prozess von Aufnahme bis zum (nachbearbeiteten) Modell integrieren.
<br><br>
In dieser Demo verwenden wir daher solch eine App, **Polycam**. Aber auch **RealityScan**, **KIRI Engine** oder **Scaniverse** stehen hier als vergleichbare Alternativen mit kleineren Unterschieden in Verf√ºgbarkeit von Features, Qualit√§t und Kostenmodell zur Verf√ºgung. 
Alle dieser Optionen sind kostenlos benutzbar, nachdem die Berechnung der 3D-Modelle aber erheblichen Rechenaufwand f√ºr den Anbieter erzeugt besteht oft eine Limitation der kostenlosen Aufnahmen, eine Obergrenze f√ºr die Anzahl an Fotos pro Aufnahme, oder begrenzte Export-Dateiformate, etc. (Einzige Ausnahme ist **Scaniverse**, dort wird die Modellrekonstruktion lokal berechnet - was jedoch hohe Rechenlast erzeugen kann und die finale Qualit√§t einschr√§nkt)
<br><br>
Alle Apps k√∂nnen je nach Smartphone √ºber den Google Play Store oder den Apple App Store installiert werden.


|              |                                                                                           |                                                                                |
| ------------ | :---------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------: |
| Polycam:     |         [Android](https://play.google.com/store/apps/details?id=ai.polycam&hl=en)         |   [iOS](https://apps.apple.com/de/app/polycam-lidar-3d-scanner/id1532482376)   |
| RealityScan: | [Android](https://play.google.com/store/apps/details?id=com.epicgames.realityscan&hl=en)  | [iOS](https://apps.apple.com/de/app/realityscan-3d-scanning-app/id1584832280)  |
| KIRI Engine: |     [Android](https://play.google.com/store/apps/details?id=com.kiriengine.app&hl=en)     | [iOS](https://apps.apple.com/de/app/kiri-engine-3d-scanner-lidar/id1577127142) |
| Scaniverse:  | [Android](https://play.google.com/store/apps/details?id=com.nianticlabs.scaniverse&hl=en) |    [iOS](https://apps.apple.com/de/app/scaniverse-3d-scanner/id1541433223)     |


Nach Installation der gew√§hlten App ist in den meisten F√§llen auch die Registrierung eines Benutzerkontos n√∂tig - **das Abschlie√üen eines kostenpflichtigen Abos ist jedoch bei keiner dieser Apps notwendig!** Das Tutorial kann mit den kostenlos verf√ºgbaren Features durchgef√ºhrt werden.

#### Vorbereitung - Objekt & Umgebung

I. Objekt
===

Nat√ºrlich ben√∂tigen wir auch noch ein Objekt, von dem wir ein 3D-Modell erzeugen wollen. In der Praxis wird der gesamte Aufnahmeprozess selbstverst√§ndlich f√ºr ein bestimmtes Objekt oder eine Objektgruppe geplant - um sich mit der Methodik vertraut zu machen empfiehlt sich hier aber im ersten Anlauf die Wahl eines gut geeigneten Objekts. Auf die technische Grundlage der Methode zur√ºckblickend ergeben sich hierf√ºr zwei prim√§re Anforderungen:


* Auf der Oberfl√§che des Objekts m√ºssen **Features** erkannt werden k√∂nnen
  
  d.h. gro√üe glatte & einfarbige Fl√§chen eignen sich nicht gut f√ºr die Photogrammetrie

* Die erkennbaren **Features** m√ºssen aus benachbarten Perspektiven wiedererkennbar sein

  d.h. transparente & stark reflektive Oberfl√§chen, deren Aussehen stark blickwinkelabh√§ngig ist sind ebenfalls nicht optimal


Eben diese Anforderungen stellen auch die gr√∂√üte Limitation der Photogrammetrie dar, mit spezieller Belichtung, Polfiltern oder Oberfl√§chensprays kann diesen Problemen oft entgegengewirkt werden, dies ist jedoch mit zus√§tzlichem Aufwand verbunden und keine Garantie f√ºr Erfolg.
<br><br>

II. Umgebung
===

Der wichtigste Umgebungsfaktor f√ºr die Aufnahme besteht in der Beleuchtung unserer Szene - je geringer der direkte Lichteinfall ist, desto besser. Gleichzeitig soll das Objekt nat√ºrlich ausreichend beleuchtet sein, um gut erkannt und abgebildet zu werden. Das Optimum besteht in einer diffusen, gleichm√§√üigen Ausleuchtung des Raumes ohne direkte "Lichtbestrahlung". Bei 3D-Aufnahmen im Freien eignen sich insbesondere helle, aber bedeckte Tage, in geschlossenen R√§umen werden bestenfalls sogennante *Softboxen* oder Fotozelte verwendet. Zum Zwecke dieses Tutorials reicht es allerdings vollkommen aus, das Objekt nicht zu direkt "anzustrahlen".
<br><br>
Eine leerger√§umte Tischplatte reicht vorerst absolut als Hinter- bzw. Untergrund f√ºr die Aufnahme aus. Stark gef√ºllte & bunte Hintergr√ºnde k√∂nnen in manchen F√§llen zur Fehlerquelle werden (F√ºhrt zu vielen zus√§tzlichen Features im Hintergrund -> Gut f√ºr die Orientierung der Kameras, kann aber die Objektrekonstruktion st√∂ren).<br><br>

<div>
    <img src="res/setup_minimal.JPG" alt="Minimales Photogrammetrie-Setup" style="float:left;width:48%"/>
    <img src="res/setup_improved.JPG" alt="Photogrammetrie-Setup inklusive Softboxen, Drehteller, DSLR-Kamera + Stativ & Fernausl√∂ser" style="float:right;width:48%"/>
    <div style="float:left;width:48%;text-align:center">
      *'Minimales' Photogrammetrie-Setup*
    </div>
    <div style="float:right;width:48%;text-align:center">
      *Erste Aufr√ºstungsm√∂glichkeiten: Softbox-Beleuchtung, Drehteller, DSLR Kamera inkl. Stativ & Fernausl√∂ser*
    </div>
</div>

#### Capturing
<br><br>



<div style="overflow:auto">

  <div style="float:right;width:20%;margin: 5px 20px 20px 50px;">
    <img src="res/poly_start.jpg" alt="Start-Ansicht von Polycam" style=""/>
    <p style="text-align:center"> *Start-Ansicht von Polycam* </p>
  </div>

<p style="text-align:center"> Wie nehme ich auf?
=== </p>

  Ist alles vorbereitet kann es nun an die eigentliche Aufnahme gehen.
  <br>
  √ñffnet man **Polycam**, wird man direkt mit dem Aufnahme-Interface begr√º√üt, bei manchen anderen Apps muss manuell eine **Neue Aufnahme/New Capture** ge√∂ffnet werden.
  Die einzige verf√ºgbare Einstellung ist hier die Auswahl zwischen der Aufnahme einzelner Photos ('Manual') und der "Video"-Aufnahme ('Auto'). Um die Aufnahme verwackelter Bilder w√§hrend der Bewegung bzw. Umpositionierung zu vermeiden, empfiehlt sich hier die manuelle Aufnahme.

  Das einfachste "Aufnahmemuster", um eine gute Abdeckung zu erreichen ist das kreisf√∂rmige Umrunden des Objekts bei regelm√§√üigem Fotografieren, beispielsweise alle 10-20¬∞ (~20 Bilder/Umrundung) oder frei Hand nach jedem "Seitw√§rtsschritt"(siehe Abbildung).
  Um die Abdeckung weiterhin zu verbessern werden diese Umrundungen auf verschiedenen H√∂hen wiederholt (min. 2-3 mal; z.B. eine Umrundung je auf Augenh√∂he/Brusth√∂he/H√ºfth√∂he, angepasst an Objekt- und Tischgr√∂√üe nat√ºrlich).
  <br><br>
  <div style="float:left;width:30%;margin: 5px 20px 20px 0px;">
    <img src="res/capturing_slow.gif" alt="Der Aufnahmeprozess" style=""/>
    <p style="text-align:center"> *rudiment√§re Aufnahme-Methodik* </p>
  </div>
  Bei einfachen Objekten ist eine Gesamtaufnahme von ca. 40-50 Bildern (2 Ringe zu je 20-25 Bildern) bereits ein zuverl√§ssiges Mindestma√ü. Sp√§testens 3-4 Ringe zu je 30-40 Bildern sind in den meisten F√§llen ausreichend.

  <img src="res/sfm.gif" alt="klassische ringweise Aufnahmestrategie" style="width:100%">
  <p style="text-align:center"> *beispielhaftes Photogrammetrie-Aufnahmemuster* </p>

</div>

<br><br>

<div style="overflow:auto;">

<p style="text-align:center"> Probleme?
=== </p>

  **Ich habe nicht genug Platz, um das Objekt zu umrunden?**
  <br>
  Fast alle Photogrammetrie-Apps unterst√ºtzen das sogenannte *Object Masking*, hierbei wird versucht das "Zielobjekt" der Aufnahme zu identifizieren und nachfolgend all **Features** abseits des Objektes ignoriert. Dadurch besteht praktisch kein Unterschied mehr zwischem einem "Herumlaufen" um das Objekt und einer schrittweisen Rotation des Objektes selbst. Achtung - bei weichen, deformierbaren Objekten besteht die Gefahr das Objekt zu verformen, hier empfiehlt sich ein Drehteller oder anderweitige Unterlage, mittels der das Objekt gedreht werden kann.

  <!--- TODO: Kommentar 'Belichtung'?(MH) --->

  **So wird ja die Unterseite des Objektes garnicht gesehen!**
  <br>
  Richtig, auch hier kann aber das *Object Masking* helfen. Solide Objekte k√∂nnen dabei beliebig umgedreht, hingelegt und rotiert werden, ohne die Rekonstruktion zu beeintr√§chtigen. Dadurch kann auch die Unterseite mit aufgenommen werden. Dies gestaltet sich bei deformierbaren Objekten jedoch schwierig, Option ist hier das Aufh√§ngen oder anderweitige Suspendieren in der Luft, um auch kreisf√∂rmige Photo Aufnahmen von unterhalb aufnehmen zu k√∂nnen.

  <div style="overflow:auto">
    <div style="float:left;width:48%;">
      <img src="res/series_no_mask.png" alt="Photoseries" />
    </div>
    <div style="float:right;width:48%;">
      <img src="res/series_with_mask.png" alt="Photoserie mit Bedarf f√ºr *Object Masking*" />
    </div>
  </div>
  <div style="overflow:auto">
    <div style="float:left;width:48%;">
      <p style="text-align:center"> *Photoserie ohne Bedarf f√ºr *Object Masking* <br>(Kamera bewegt sich um Objekt, Objekt ist statisch im Bezug auf Umgebung)* </p>
    </div>
    <div style="float:right;width:48%;">
      <p style="text-align:center"> *Photoserie mit Bedarf f√ºr *Object Masking* <br>(Kamera statisch, Objekt wird gedreht und verschiebt sich im Bezug auf Umgebung)* </p>
    </div>
  </div>

</div>

<br><br>

<p style="text-align:center"> Alles fertig?
=== </p>

Sind alle gew√ºnschten Blickwinkel auf das Objekt ausreichend abgedeckt, kann die Aufnahme beendet werden.
Abschlie√üend kann noch die gew√ºnschte Qualit√§t des 3D-Modells (beeinflusst auch die Dateigr√∂√üe! - am besten 'Medium' oder 'Full') eingestellt, und bei Bedarf das bereits erw√§hnte *Object Masking* aktiviert werden.

<div style="overflow:auto">
    <div style="margin-top:40px;margin-bottom:20px;margin-left:auto;margin-right:auto;width:80%;">
      <img src="res/Polycam_finished_v2.png" alt="Abschluss der Aufnahme" />
    </div>
  </div>
  <div style="overflow:auto">
    <div style="float:left;width:40%;">
      <p style="text-align:center;margin-left:auto;margin-right:auto;width:60%"> *Im *Review*-Modus k√∂nnen bisher genommene Photos √ºberpr√ºft und bei Bedarf wieder entfernt werden.* </p>
    </div>
    <div style="float:right;width:40%;">
      <p style="text-align:center;margin-left:auto;margin-right:auto;width:60%"> *Bei Projekt-Abschluss k√∂nnen gew√ºnschte Qualit√§t sowie *Object Masking* eingestellt werden.* </p>
    </div>
  </div>

Da die Erstellung des 3D-Modells sehr rechenintensiv ist, wird der Prozess nicht lokal auf dem Smartphone gestartet. Stattdessen verwenden alle Photogrammetrie-Apps an dieser Stelle *Cloud Computing*, wobei die aufgenommenen Bilder an einen Server geschickt werden, der die Berechnung √ºbernimmt (WLAN verwenden, um √ºberm√§√üigen Datenverbrauch zu vermeiden). Klassischerweise ergibt sich daraus eine Wartezeit von ca. 5-10 Minuten, bis das fertige Objekt in der Projekt-Gallerie der App betrachtet werden kann.

<br><br><br>
***Erfolg! - Schon haben wir ein erstes eigenes 3D-Modell erzeugt!***


## Part 2 - Modellfehler & Nachbearbeitung

Ein wichtiger Schritt bei der Erzeugung hochwertiger 3D-Digitalisate besteht in der richtigen Nachbearbeitung der Modelle.
Je nach Verwendungszweck kann die Nachbearbeitung im "Low-End"- & Hobbybereich der Photogrammetrie noch recht knapp ausfallen, unter anderem weil viele Photogrammetrie-Apps bereits einige automatisierte Nachbearbeitungsschritte durchf√ºhren. Bei h√∂heren Qualit√§tsanspr√ºchen und der Notwendigkeit f√ºr individuelle Nachbearbeitung steigt dieser Aufwand jedoch schnell.
<br><br>
Auch wenn das erzeugte Modell auf den ersten Blick gut rekonstruiert scheint, gibt es noch einige Anhaltspunkte, die gepr√ºft und bei Bedarf nachgebessert werden sollten, um das Digitalisat weiterverwendbar zu machen.
Die h√§ufigsten Problemf√§lle & Optimierungsm√∂glichkeiten und wie wir mit ihnen umgehen k√∂nnen, wollen wir uns jetzt genauer anschauen.

Um das Objekt genauer zu betrachten und zu ver√§ndern, w√§hlen wir es aus der Projektgallerie aus und kommen dadurch in das Bearbeitungsmen√º.

üí° **Tipp:** Polycam besitzt auch ein [Webinterface](https://poly.cam). Wenn ihnen ein Desktop-PC oder Laptop zur Verf√ºgung steht, haben sie auch dort Zugriff auf alle bereits an den Server √ºbermittelten Projekte. Die Nachbearbeitung ist hier√ºber meist angenehmer als √ºber ein Smartphone-Touchscreen.

<!---
![Image](res/edit_mode.png)
--->

#### Origin<br>
Jedes 3D-Modell verf√ºgt √ºber einen sogenannte *Origin* (= Ursprung). Dieser stellt den Aufh√§ngungspunkt und Rotationsmittelpunkt des Objektes dar, und ist insbesondere beim sp√§teren Import des Modells in weiterer Software relevant.

Problematisch ist insbesondere, wenn der *Origin* (weit) au√üerhalb des eigentlichen *Meshes* liegt.
F√ºr die optimale Position des *Origin* besteht jedoch keine feste Definition, er kann ja nach Nutzerpr√§ferenz in den "Masseschwerpunkt", zentral auf die Bodenfl√§che des Objekts oder anhand gew√ºnschter Rotationsachsen gesetzt werden.

Automatisierte Photogrammetrie-Pipelines setzen den *Origin* meist automatisch auf den Mittelpunkt und erlauben dar√ºber hinaus oft keine weitere Bearbeitung. Ist eine Bearbeitung erw√ºnscht, muss zus√§tzliche Software (**Blender**, **MeshLab**) hinzugezogen werden.<br><br>

<div>
    <img src="res/wrong_origin.gif" alt="Import eines Modells mit fehlerhaftem *Origin* in Blender" style="float:left;width:48%"/>
    <img src="res/right_origin.gif" alt="Import eines Modells mit korrigiertem *Origin* in Blender" style="float:right;width:48%"/>
    <div style="float:left;width:48%;text-align:center">
      *Import eines 3D-Modells mit fehlerhaftem* Origin (**Blender**)
    </div>
    <div style="float:right;width:48%;text-align:center">
      *Import eines 3D-Modells mit korrigiertem* Origin (**Blender**)
    </div>
</div>

<!--- TODO: add rotation of wrong origin model? --->

#### Rotation<br>
√Ñhnlich zum *Origin* ist auch die Orientierung des Objektes oft unerwartet im Verh√§ltnis zu den Hauptachsen der 3D-Szene.
Da die Software meist nicht von selbst feststellen kann, wo bspw. "oben" ist, wird die Rotation z.T. arbitr√§r gesetzt, dadurch entsteht unerw√ºnschtes Verhalten beim Drehen und Bewegen des Objektes und beim Import in andere 3D-Software.<br>
Hier gibt uns Polycam die M√∂glichkeit, das Objekt neu zu Orientieren. Dazu kann das Objekt unter **Rotate** mittels des bunten "Anfassers" gedreht werden, bis die gew√ºnschte Orientierung im Bezug zu der Bodenfl√§che (graues Gitter) erreicht ist. Wird die √Ñnderung angewendet, sollte ein merklich nat√ºrlicheres Rotationsverhalten zu beobachten sein.

<div style="overflow:auto">
  <img style="float:left;width:30%;margin-right:5%;text-align:center;" src="res/rotation_wrong.gif" alt="">
  <img style="float:left;width:30%;text-align:center;" src="res/rotation_fix.gif" alt="">
  <img style="float:left;width:30%;margin-left:5%;text-align:center;" src="res/rotation_right.gif" alt="">
</div>

<div style="overflow:auto">
  <p style="float:left;width:30%;margin-right:5%;text-align:center;">*Schlechtes Rotationsverhalten*</p>
  <p style="float:left;width:30%;text-align:center;">*Anpassung der Rotation*</p>
  <p style="float:left;width:30%;margin-left:5%;text-align:center;">*Korrigierte Rotationsachsen*</p>
</div>

#### Skalierung<br>
Auch die Gr√∂√üe des Originalobjekts ist h√§ufig nicht korrekt im 3D-Modell abgebildet. Dies ist abermals beim Import in andere 3D-Szenen ein Problem, aber auch bspw. bei der Analyse und Beforschung eines digitalisierten Objekts.
Zur Korrektur k√∂nnen unter **Rescale** Punkte auf dem Modell ausgew√§hlt werden, deren reale Distanz voneinander bekannt ist bzw. ausgemessen wurde (Bei professioneller Anwendung werden hierf√ºr standartisierte Marker am oder neben dem Objekt angebracht). Die Distanz der Punkte in der digitalen Szene kann dann dementsprechend angepasst werden. Die Bearbeitung hat keine offensichtlichen Folgen in der 3D-Ansicht, wohl aber auf den Export des Modells.

<img src="res/scale_fix.gif" alt="Anpassung der Objekt-Skalierung" style="width:100%;margin-left:0%"/>
<p style="text-align:center"> *Anpassung der Objekt-Skalierung anhand bekannter/gemessener Distanzen* </p>

#### Outlier<br>
Als *Outlier* (= Ausrei√üer) versteht man bei 3D-Modellen einzelne Punkte, Kanten oder Fl√§chen (die Grundbausteine eines *Meshes*), die nicht mit dem Hauptobjekt verbunden sind - diese Artefakte entstehen entweder aus falsch erkannten *Features* bei der Modellberechnung oder sp√§ter bei der Umwandlung der Punktewolke zum *Mesh*. Eine grundlegendes *Outlier Removal* wird von den meisten Photogrammetrie-Apps standartm√§√üig durchgef√ºhrt. Dar√ºber hinaus gibt es in Polycam keine manuelle Bearbeitungsm√∂glichkeit.

<img src="res/outlier.png" alt="fehlerhafte Rekonstruktion bei der Aufnahme einer Nike-Gipsstatuette" style="width:100%;margin-left:0%"/>
<p style="text-align:center"> *Beispiel eines fehlerhaft rekonstruierten Objekts mit ****Outlier****-Artefakten (Blender)* </p>

#### Hintergrund<br>
Insbesondere bei der Photogrammetrie ohne *Object Masking* beinhaltet die rekonstruierte Szene meist noch Teile und Objekte des Hintergrundes (Tischplatte, W√§nde, zus√§tzliche Objekte).
Sofern die Digitalisierung des gesamten Raumes bzw. der Gesamtszene jedoch nicht Ziel der Aufnahme war, ist es sinnvoll die Szene auf das gew√ºnschte Objekt zu reduzieren.<br>
Hierf√ºr kann via **Crop** entweder eine Box oder ein Zylinder definiert und √ºber die "Anfasser" angepasst werden, die ausschlie√ülich das Objekt beinhalten. Oder es werden √ºber die **Crop Out** Option in mehreren Schritten einzelne unerw√ºnschte Teile des Objektes weggeschnitten.<br><br>

<img src="res/crop_fix.gif" alt="Object *Cropping* in Polycam" style="width:100%;margin-left:0%"/>
<p style="text-align:center"> *Anwendung der ****Crop In****-Bearbeitung in Polycam </p>


<!--- 
  ![Image](res/edit_crop_out.png) 
--->

<!---
#### Farbe & Ton<br>
Ist die allgemeine F√§rbung des Objektes nicht zufriedenstellend, k√∂nnen gewisse √Ñnderungen bzgl Farbs√§ttigung, Kontrast, Temperatur etc. auch nachtr√§glich noch unter **Color** angepasst werden.
Sind jedoch nur stellenweise unerw√ºnschte Verf√§rbungen oder Hell-Dunkel-Wechsel aufgetreten ist dies h√§ufig ein Hinweis auf ungleiche/unausreichende Beleuchtung des Objektes bei der Aufnahme - derartige Fehler sind schwer nachtr√§glich zu beheben und erfordern oft eine Neuaufnahme des Objektes.

![Image](res/edit_tonemap.png)
--->

#### Geometrie-Aufl√∂sung/Dateigr√∂√üe<br>
Je nach Verwendungszweck des 3D-Modells bestehen oft sehr spezifische Anforderungen an den Detailgrad der Geometrie oder die allgemeine Dateigr√∂√üe.<br>
Die Aufl√∂sung zu erh√∂hen ist im Nachhinein nur schwer m√∂glich und erfordert eine Neuberechnung des Modells mit anderen Detaileinstellungen und/oder mehr bzw. besseren Aufnahmebildern.<br>
Eine Reduktion der Aufl√∂sung/Dateigr√∂√üe, um beispielsweise das Datenlimit einer Webseite zu erf√ºllen, ist wiederum in fast jeder Photogrammetrie-Software nachtr√§glich m√∂glich.

> ‚ö†Ô∏è *Hinweis - Dieses Bearbeitungsfeature ist ****nicht**** Teil der kostenlosen Features von Polycam!*<br><br>
> *F√ºr die laienhafte Anwendung der Photogrammetrie und Weiterverwendung der Modelle ist eine Reduktion der Geometrie-Aufl√∂sung aber meistens auch nicht notwendig - Der Bedarf besteht insbesondere bei sehr hochaufgel√∂sten Modellen, die nachfolgend f√ºr die Webpublikation optimiert werden sollen.*
> 
> In Polycam kann unter **Remesh** ein expliziter Reduktionsfaktor oder eine gew√ºnschte Polygonzahl (Anzahl einzelner Fl√§chen im *Mesh*) angegeben werden. Die Einstellung **Uniform** sorgt dabei f√ºr eine gleichm√§√üige Reduktion der Aufl√∂sung √ºber das *Mesh* hinweg. Bei **Adaptive** wird versucht, an detailreichen Stellen des Objektes eine h√∂here Aufl√∂sung zu bewahren, w√§hrend sie an detail√§rmeren Stellen im Ausgleich st√§rker reduziert wird.
> Auch die Textur-Aufl√∂sung kann reduziert werden. Der Einflu√ü auf die Dateigr√∂√üe ist aber h√§ufig geringer als im Falle der Geometrie-Aufl√∂sung.

<!---
![Image](res/edit_remesh.png)
--->

#### Textur- & Geometrie-Fehler<br>
Bei der Berechnung des 3D-Modells k√∂nnen k√∂nnen sowohl Geometrie als auch Texturen falsch rekonstruiert werden.
Dies ist meist ein Indiz f√ºr schlechte Abdeckung der betreffenden Bereiche bei der Aufnahme oder f√ºr problematische Materialien (reflektive/transparente Objektteile). Durch einfache Nachbearbeitung ist dies kaum zu beheben, entweder m√ºssen die fehlerhaften Bereiche in einem externen Programm manuell nachmodelliert werden, oder es wird eine Neuaufnahme versucht.

Eine dritte Option besteht hier je nach Software noch in der Erweiterung der bisherigen Aufnahme um zus√§tzliche Bilder. Polycam bietet dazu die **Extend**-Option an. Diese versetzt den Nutzer zur√ºck in den Aufnahmemodus, bei der Modellberechnung werden dann sowohl neue als auch vorhergehende Bilder miteinbezogen.<br>

> ‚ö†Ô∏è *Hinweis - Die ****Extend****-Option ist nur in der Smartphone-App verf√ºgbar, nicht im Webinterface von Polycam*

<br>

<div>
    <img src="res/nike_error.png" alt="Geometrie- & Texturfehler aufgrund unpr√§ziser Rekonstruktion" style="float:left;width:48%"/>
    <img src="res/camera_error.png" alt="Rekonstruktionsfehler aufgrund der Reflektivit√§t der Linse" style="float:right;width:48%"/>
    <div style="float:left;width:48%;text-align:center">
      *Geometrie- & Texturfehler aufgrund unpr√§ziser Rekonstruktion*
    </div>
    <div style="float:right;width:48%;text-align:center">
      *Rekonstruktionsfehler aufgrund der Reflektivit√§t der Linse*
    </div>
</div>

#### Dateiformat bei Export<br>
Eine Weiterverwendung des Modells setzt selbstverst√§ndlich einen Export der Modelldatei voraus. W√§hrend eine nachtr√§gliche Umwandlung zwischen Dateiformaten oft m√∂glich ist, gehen in manchen Formaten Informationen verloren.<br>
Der Export in **Polycam** ist √ºber das *Download*-Symbol zug√§nglich. Leider ist die Wahl des Exportformates in vielen Photogrammetrie-Apps ein kostenpflichtiges Feature - bei Polycam wird bspw. nur der Export als .glb/.gltf-Datei kostenfrei angeboten. Insbesondere f√ºr Weiterverwendung im Webkontext ist dieses Format inzwischen der de-facto Standart und kann problemlos f√ºr die Publikation des Objektes auf Webseiten oder √Ñhnlichem verwendet werden. 

<img src="res/polycam_export.png" alt="√úbersicht der Export-Dateiformate von Polycam">
<p style="text-align:center"> *Kostenlos k√∂nnen in **Polycam** nur das Mesh im *.glb/.gltf*-Format sowie die aufgenommene Bilderserie heruntergeladen werden.* </p>
 
#### Ausblick
Wie bereits erw√§hnt ist insbesondere bei voll-automatisierter Photogrammetrie-Software sowohl der Bedarf nach Nachbearbeitung als auch die M√∂glichkeit dazu eher beschr√§nkt. Viele Optimierungen werden auf sehr generelle Weise automatisch durchgef√ºhrt anstatt spezifische Einstellungen vom Nutzer entgegenzunehmen oder zu verlangen. Umfangreichere, industrieller orientierte Software bietet hier mehr Freiheiten, fordert aber auch oft eine tiefergehende Auseinandersetzung mit der Software und den einzelnen Nachbearbeitungsschritten. Zus√§tzlich besteht unabh√§ngig von der Photogrammetrie-Software noch die M√∂glichkeit zur Nachbearbeitung in externer 3D-Software. Zum Beispiel in der 3D-Modellierungs & Animations-Software **Blender** k√∂nnen alle beschriebenen und viele weitere Nach- und Weiterverarbeitungsschritte vorgenommen werden. Da jedoch ausschlie√ülich die Photogrammetriesoftware selbst √ºber die Rohdaten der Rekonstruktion verf√ºgt, ist es empfehlenswert, alle m√∂glichen Nachbearbeitungen bereits dort vorzunehmen. Je nach Exportformat gehen ansonsten Teilinformationen verloren, wodurch die m√∂gliche Qualit√§t einer externen Nachbearbeitung eingeschr√§nkt werden kann.

## Part 3 - Publikation

Im letzten Kapitel dieses kleinen Tutorials wollen wir uns noch mit der Publikation von 3D-Modellen im Web besch√§ftigen.
Insbesondere im Vergleich mit anderweitigen Digitalisaten sind 3D-Modelle sehr anschaulich und greifbar - dadurch eignen sie sich √§u√üerst gut f√ºr die Repr√§sentation einer Sammlung der allgemeinen √ñffentlichkeit gegen√ºber.
Durch Vertretung der Sammlung auf gro√üen 3D-Webportalen wie **Sketchfab**, die viel √ñffentlichkeitsverkehr erleben, kann auch Aufmerksamkeit in neuen Zielgruppen generiert werden.
Wir betrachten im Folgenden daher die Publikation von 3D-Modellen auf **Sketchfab** und setzen uns zuletzt noch mit alternativen M√∂glichkeiten der Webpublikation auseinander.

#### Weiterverwendung von 3D-Modellen

Nach der Erzeugung und erfolgreichen Nachbearbeitung kann und soll das 3D-Modell nun auch verwendet werden. 
Die genaue Art und Weise der Nutzung sollte sofern m√∂glich im Vorhinein geplant sein, da Aufnahmesetup & -qualit√§t sowie die Nachbearbeitung f√ºr die Weiternutzung optimiert werden m√ºssen.

In unserem Fall wollen wir das Modell √∂ffentlich zur Verf√ºgung stellen, ohne eine eigene Webseite oder eigene Serverkapazit√§ten aufwenden zu m√ºssen. Daher f√§llt auch hier die Wahl wieder auf einen Webanbieter.
Die bekanntesten Optionen zur Zeit sind Sketchfab, ein allgemeiner Markt- & Austauschplatz f√ºr 3D-Modelle mit sehr gro√üem Publikum aber leider noch ungekl√§rter Zukunft, sowie kompakkt, eine kleinere, nicht-kommerzielle Alternative, die allerdings mit Fokus auf Digital Humanities-Bedarfe entwickelt wurde.

Aufgrund der Popularit√§t von **Sketchfab**, und da neue **kompakkt**-Nutzer die Uploadfunktion erst manuell von Seiten der Betreiber genehmigt bekommen m√ºssen, werden wir uns f√ºr dieses Tutorial an **Sketchfab** halten, der Uploadprozess beider Seiten √§hnelt sich jedoch stark.

#### Publikation auf Sketchfab

[Sketchfab](sketchfab.com) ist ein Webportal zum Austausch und Verkauf von 3D-Modellen jeglicher Art. W√§hrend die l√§ngerfristige Zukunft von Sketchfab derzeit noch ungekl√§rt ist (bevorstehende Migration auf das kommerzieller orientierte [FAB](https://fab.com)), hat sich hier bereits ein reicher Schatz an Kulturerbe-Digitalisaten angesammelt ([Kulturerbe-Inhalte](https://sketchfab.com/3d-models/categories/cultural-heritage-history) auf Sketchfab).

Auch Sketchfab erwartet vor der Nutzung wieder eine kostenlose Registrierung von seinen Nutzern. Nach Mail-Verifikation, optionaler Profileinrichtung und Wahl des Abonnements (kein kostenpflichtiges Abo notwendig!) kann direkt losgelegt werden. Nach Wahl der **Upload**-Option kann √ºber den Dateibrowser oder Drag-and-Drop das gew√ºnschte 3D-Modell ausgew√§hlt werden.

![Image](res/sketchfab_upload.gif)

Nach Auswahl der Datei √∂ffnet sich das Bearbeitungsmen√º des neuen Eintrags. Bis das Modell selbst geladen ist und testweise betrachtet werden kann braucht es meist noch einen Moment Geduld.

![Image](res/sketchfab_pick_file.gif)

Ist das Modell fertig geladen, kann es √ºber das kleine Viewer-Fenster betrachtet werden oder direkt √ºber die Option **Edit 3D Settings** nochmals bearbeitet werden.
Da **Sketchfab** einen anderen *Renderer* (= 3D-Darstellungsprogramm) als **Polycam** verwendet, sehen viele Objekte erstmal anders aus. Standartm√§√üig wird die Beleuchtung hier einem industriellen Innenraum nachempfunden. Setzt diese Beleuchtung das Objekt nicht angemessen in Szene, kann die Beleuchtung entweder manuell nach Wunsch eingestellt werden (Lampen-Symbol), oder auf die Beleuchtungssimulation verzichtet und durch die **Shadeless**-Option die ungefilterte Darstellung der rekonstruierten Objektfarben erzwungen werden.

![Image](res/sketchfab_lighting.gif)

Ist die Sichtbarkeit durch den Hintergrund behindert, kann auch dieser hier angepasst werden. 
Um das Objekt von seiner besten Seite zu pr√§sentieren, kann, neben vielen weiteren √Ñnderungen, auch eine vorteilhafte initiale Kameraposition definiert werden.
Um das Objekt rein zur interessierten Betrachtung zu Ver√∂ffentlichen, ist an dieser Stelle aber auch kein gro√üer Aufwand erforderlich.
<br>
Relevante Einstellungen sind zudem die Sichtbarkeit (Bei kostenfreier Nutzung zwangsweise "√∂ffentlich") und  unter welcher Lizenzierung (falls √ºberhaupt) das Modell anderen Nutzern zum Download zur Verf√ºgung gestellt werden soll.
Nach Wahl eines passenden Titels und einer (optionalen) kurzen Beschreibung kann das Modell mit einem Klick auf **Publish** ver√∂ffentlicht werden!

![Image](res/sketchfab_publish.gif)

Das fertige Modell ist ab sofort √∂ffentlich auf **Sketchfab** verf√ºgbar und kann von allen Interessierten betrachtet werden, und je nach Freigabe auch heruntergeladen und weiterverwendet werden.
<br><br><br>
***Gl√ºckwunsch! Wer bis hierhin mitgemacht hat, hat nun erfolgreich sein erstes eigenes Digitalisat erschaffen, nachbearbeitet & publiziert!***



#### Alternativen

Je nach gew√ºnschter Verwendung und eigenen M√∂glichkeiten & W√ºnschen bestehen viele Alternativen f√ºr die Verwendung von 3D-Modellen im Web.
Folgende Kriterien k√∂nnen beispielsweise ausschlaggebend sein:

> ***Verwendungszweck***<br>
> 
> - Datenspeicherung und √∂ffentliche Verf√ºgbarkeit? -> Forschungsdatenportale wie das vom CERN gehostete [**Zenodo**](https://zenodo.org/) bieten sich an
> 
> - Reine Webbetrachtung? -> Einfache Web-Viewer wie von [**Sketchfab**](https://sketchfab.com/), [**kompakkt**](https://www.kompakkt.de/) oder [**modelviewer.js**](https://modelviewer.dev/) reichen aus
> 
> - Storytelling und kuratierte Zusatzinformation? -> f√ºr den Heritage-Sektor optimierte Viewer wie der [**Smithsonian Voyager**](https://smithsonian.github.io/dpo-voyager/) bieten L√∂sungen

> ***Ort der Datenspeicherung***<br>
> 
> - D√ºrfen die Daten auf √∂ffentliche/kommerzielle Server gelangen? -> **Sketchfab**, **kompakkt**, **Zenodo**
> 
> - Sollen die Daten im eigenen Haus bleiben und selbst gehostet werden? -> Open-Source Viewer wie **modelviewer.js** oder **Smithsonian Voyager** k√∂nnen in eigene Webauftritte integriert werden, ohne die 3D-Daten aus der eigenen Hand zu geben

> ***Technische Kapazit√§t***<br>
> 
> - Reiner Endnutzer? -> fertige, alleinstehende Produkte wie **Sketchfab** und **Smithsonian Voyager** sind auch ohne technisches Vorwissen leicht zu verwenden
> 
> - Mittlere IT-Kapazit√§ten? -> Viewer wie **Smithsonian Voyager** oder **modelviewer.js** k√∂nnen schnell an spezifische Anwendungszwecke angepasst werden
> 
> - Gro√üe IT-Kompetenzen/IT-Abteilung? -> Auf Basis von **three.js** oder sogar dem darunterliegenden **WebGL** k√∂nnen arbitr√§re 3D-Webanwendungen entwickelt werden



